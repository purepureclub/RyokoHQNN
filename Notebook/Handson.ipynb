{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a34fde6e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# リョウコと実装！量子機械学習で手書き文字認識\n",
    "\n",
    "みなさん、「リョウコと実装！量子機械学習で手書き文字認識」へようこそ。機械学習は、量子コンピューターの応用範囲として期待されているエリアのひとつです。本ハンズオンでは、機械学習の中でも量子古典ハイブリッド・ニューラルネットワークを用いた手書き文字認識を取り上げます。MNISTを利用した量子古典ハイブリッド・モデルの学習方法と使用方法を紹介し、実際に手書き文字を認識するWebアプリを体感していただきます！\n",
    "\n",
    "前提知識：Python 、ニューラルネットワーク、IBM Cloud\n",
    "\n",
    "事前準備：[IBM Quantum](https://quantum-computing.ibm.com/)へのサインアップ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffbf28a",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## 目次\n",
    "\n",
    "1. [はじめに](#introduction)\n",
    "1. [量子古典ハイブリッド・ニューラルネットワーク](#hybrid)\n",
    "1. [実装！](#implementation)\n",
    "1. [まとめ](#summary)\n",
    "1. [参考文献](#reference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695ce7fd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## はじめに <a id='indroduction'></a>\n",
    "まずは、ハンズオンを実行する環境を準備しましょう。\n",
    "\n",
    "1. ハンズオンで使用するJupyter notebookファイル(zipファイル)を[こちら](https://github.com/purepureclub/RyokoHQNN/archive/refs/heads/main.zip)からダウンロードします\n",
    "1. ダウンロードしたzipファイルを解凍します\n",
    "1. [IBM Quantum](https://quantum-computing.ibm.com/) にログインします\n",
    "1. IBM QuantumのDashbord上のLaunch Labボタンをクリックします\n",
    "1. Upload Filesボタン(上矢印)を押して、解凍したファイルをアップロードします\n",
    "1. アップロードしたファイル「Handson.ipynb」を開いてください"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6978b1d8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "次に、必要なモジュールとライブラリをインポートしておきましょう。Jupyter notebookでは、セルにカーソルを置き、Shift+Enterを押すと、セル内のコードが実行されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357309bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import cat, no_grad, manual_seed\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim as optim\n",
    "from torch.nn import (\n",
    "    Module,\n",
    "    Conv2d,\n",
    "    Linear,\n",
    "    Dropout2d,\n",
    "    NLLLoss,\n",
    ")\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit.utils import algorithm_globals\n",
    "from qiskit.circuit.library import RealAmplitudes, ZZFeatureMap\n",
    "from qiskit_machine_learning.neural_networks import EstimatorQNN\n",
    "from qiskit_machine_learning.connectors import TorchConnector\n",
    "\n",
    "# Set seed for random generators\n",
    "algorithm_globals.random_seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe209d2",
   "metadata": {},
   "source": [
    "以上で準備は完了です。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50a489b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 量子古典ハイブリッド・ニューラルネットワーク <a id='hybrid'></a>\n",
    "\n",
    "ニューラルネットワークは、ヒトのニューロンを模したシステムで、一般的に入力層に入れられたデータをもとに、出力層の数だけ分類します。\n",
    "学習により、重みやバイアスを決めて、モデルを定義します。\n",
    "![ニューラルネットワーク](NeuralNetwork.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a064dd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "量子古典ハイブリッド・ニューラルネットワークとは、その名の通り量子コンピューターと古典コンピューターのハイブリッドなニューラルネットワークのことです。古典ニューラルネットワークの一部の層を、量子コンピューターで計算する量子層で置き換えます。Qiskitの`TorchConnector`クラスを使用すると、`PyTorch`の ワークフローにQiskitで定義した量子層(`NeuralNetwork`クラス)を統合することができます。このようにして作成されたネットワークは、PyTorchの古典アーキテクチャーにシームレスに組み込むことができます。追加の考慮事項なしに古典層・量子層を同時に学習・テストすることができるのです。\n",
    "![ハイブリッド・ニューラルネットワーク](HybridNeuralNetwork1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cb0da8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "量子層は一般的に二つのパラメーター付き量子回路で実装されます。一つは古典層からの出力($\\vec{x}$)を量子データに変換(エンコーディング)する特徴マップ、もう一つは量子層の出力を計算するAnsatzです。Ansatzには最適化により決定されるパラメーター($\\vec{\\theta}$)が使用されます。Qiskitは特徴マップ、Ansatzともに簡単に実装できるクラスを提供していますので、その使い方を見ていきましょう。\n",
    "\n",
    "![Quantum Neural Network](QuantumNeuralNetwork1.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257747dc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 実装！<a id='implementation'></a>\n",
    "\n",
    "1. ステップ 1: データの準備\n",
    "1. ステップ 2: 量子古典ハイブリッド・ニューラルネットワークの構築\n",
    "1. ステップ 3: 学習\n",
    "1. ステップ 4: テスト\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d175eb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### ステップ 1: データの準備\n",
    "まず、torchvision API を利用して、 MNIST データセットをダウンロード(約70MB)し、学習用のMNISTデータ100件をロードします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4a6a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Dataset\n",
    "# -------------\n",
    "\n",
    "# Set train shuffle seed (for reproducibility)\n",
    "manual_seed(42)\n",
    "\n",
    "batch_size = 1\n",
    "n_samples = 100  # We will concentrate on the first 100 samples\n",
    "\n",
    "# Use pre-defined torchvision function to load MNIST train data\n",
    "X_train = datasets.MNIST(\n",
    "    root=\"./data\", train=True, download=True, transform=transforms.Compose([transforms.ToTensor()])\n",
    ")\n",
    "\n",
    "# Filter out labels (originally 0-9), leaving only labels 0 and 1\n",
    "idx = np.append(\n",
    "    np.where(X_train.targets == 0)[0][:n_samples], np.where(X_train.targets == 1)[0][:n_samples]\n",
    ")\n",
    "X_train.data = X_train.data[idx]\n",
    "X_train.targets = X_train.targets[idx]\n",
    "\n",
    "# Define torch dataloader with filtered data\n",
    "train_loader = DataLoader(X_train, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4588d5ce",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "サンプルデータを6件表示させてみましょう。手書きの0と1の画像で構成されていることが確認できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8d3be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples_show = 6\n",
    "\n",
    "data_iter = iter(train_loader)\n",
    "fig, axes = plt.subplots(nrows=1, ncols=n_samples_show, figsize=(10, 3))\n",
    "\n",
    "while n_samples_show > 0:\n",
    "    images, targets = data_iter.__next__()\n",
    "\n",
    "    axes[n_samples_show - 1].imshow(images[0, 0].numpy().squeeze(), cmap=\"gray\")\n",
    "    axes[n_samples_show - 1].set_xticks([])\n",
    "    axes[n_samples_show - 1].set_yticks([])\n",
    "    axes[n_samples_show - 1].set_title(\"Labeled: {}\".format(targets[0].item()))\n",
    "\n",
    "    n_samples_show -= 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f2547f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "同様にして、テスト用データ50件をロードします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5a17f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Dataset\n",
    "# -------------\n",
    "\n",
    "# Set test shuffle seed (for reproducibility)\n",
    "# manual_seed(5)\n",
    "\n",
    "n_samples = 50\n",
    "\n",
    "# Use pre-defined torchvision function to load MNIST test data\n",
    "X_test = datasets.MNIST(\n",
    "    root=\"./data\", train=False, download=True, transform=transforms.Compose([transforms.ToTensor()])\n",
    ")\n",
    "\n",
    "# Filter out labels (originally 0-9), leaving only labels 0 and 1\n",
    "idx = np.append(\n",
    "    np.where(X_test.targets == 0)[0][:n_samples], np.where(X_test.targets == 1)[0][:n_samples]\n",
    ")\n",
    "X_test.data = X_test.data[idx]\n",
    "X_test.targets = X_test.targets[idx]\n",
    "\n",
    "# Define torch dataloader with filtered data\n",
    "test_loader = DataLoader(X_test, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9194d9ee",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### ステップ2：量子古典ハイブリッド・ニューラルネットワークの構築\n",
    "量子古典ハイブリッド・ニューラルネットワークを構築するために、まず量子層を定義しましょう。今回は、Qiskitの[`EstimatorQNN`](https://qiskit.org/ecosystem/machine-learning/locale/ja_JP/stubs/qiskit_machine_learning.neural_networks.EstimatorQNN.html)クラスを使用します。`EstimatorQNN`クラスは、特徴マップとAnsatzをパラメーター化された量子回路を入力として取り込み、フォワード・パスやバックワード・パスの期待値を計算し出力します。今回は特徴マップに`ZZFeatureMap`を、Ansatzに`RealAmplitude`を使用します。後述しますが、今回量子層への入力(古典層からの出力)は2つですので、2量子ビットの`ZZFeatureMap`と`RealAmplitude`を作成します。\n",
    "\n",
    "![量子層のイメージ](QuantumNeuralNetwork2.png)\n",
    "\n",
    "[`ZZFeatureMap`](https://qiskit.org/documentation/stubs/qiskit.circuit.library.ZZFeatureMap.html) : Pauli行列を用いたエンコーディング方法([`PauliFeatureMap`](https://qiskit.org/documentation/stable/0.24/stubs/qiskit.circuit.library.PauliFeatureMap.html))の一つで、Paul行列のZとZZのみを用いたエンコーディング\n",
    "\n",
    "[`RealAmplitudes`](https://qiskit.org/documentation/stubs/qiskit.circuit.library.RealAmplitudes.html) : 化学アプリケーションや機械学習における分類回路のAnsatzとして用いられるヒューリスティックな関数。回転と量子もつれの交互の層で構成。結果として得られる量子状態は実振幅のみを持ち、複素数部分は常に0であるため、`RealAmplitudes`と呼ばれる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82762def",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Define and create QNN\n",
    "def create_qnn():\n",
    "    feature_map = ZZFeatureMap(2)\n",
    "    ansatz = RealAmplitudes(2, reps=1)\n",
    "    qc = QuantumCircuit(2)\n",
    "    qc.compose(feature_map, inplace=True)\n",
    "    qc.compose(ansatz, inplace=True)\n",
    "\n",
    "    # REMEMBER TO SET input_gradients=True FOR ENABLING HYBRID GRADIENT BACKPROP\n",
    "    qnn = EstimatorQNN(\n",
    "        circuit=qc,\n",
    "        input_params=feature_map.parameters,\n",
    "        weight_params=ansatz.parameters,\n",
    "        input_gradients=True,\n",
    "    )\n",
    "    return qnn\n",
    "\n",
    "qnn1 = create_qnn()\n",
    "qnn1.circuit.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c3a904",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "実際のどのようなゲートで実装されているか確認しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8071da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "qnn1.circuit.decompose().draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a50709",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "量子層を含めた量子・古典ハイブリッドニューラルネットワークを構築します。今回作成するネットワークの概念図は下図のようになります。\n",
    "![ハイブリッド・ニューラルネットワーク](HybridNeuralNetwork2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f0a0dd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Define torch NN module\n",
    "class Net(Module):\n",
    "    def __init__(self, qnn):\n",
    "        super().__init__()\n",
    "        self.conv1 = Conv2d(1, 2, kernel_size=5)\n",
    "        self.conv2 = Conv2d(2, 16, kernel_size=5)\n",
    "        self.dropout = Dropout2d()\n",
    "        self.fc1 = Linear(256, 64)\n",
    "        self.fc2 = Linear(64, 2)  # 2-dimensional input to QNN\n",
    "        self.qnn = TorchConnector(qnn)  # Apply torch connector, weights chosen\n",
    "        # uniformly at random from interval [-1,1].\n",
    "        self.fc3 = Linear(1, 1)  # 1-dimensional output from QNN\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        x = self.qnn(x)  # apply QNN\n",
    "        x = self.fc3(x)\n",
    "        return cat((x, 1 - x), -1)\n",
    "\n",
    "model1 = Net(qnn1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117c377f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### ステップ3: 学習！\n",
    "最適化アルゴリズムと損失関数を定義して、学習を始めます。今回は最適化アルゴリズムにAdam、損失関数にNLLossを使用します。Adamについては[こちら](https://qiita.com/omiita/items/1735c1d048fe5f611f80)を、NLLossについては[こちら](https://qiita.com/y629/items/1369ab6e56b93d39e043)が参考になると思います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd332186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model, optimizer, and loss function\n",
    "optimizer = optim.Adam(model1.parameters(), lr=0.001)\n",
    "loss_func = NLLLoss()\n",
    "\n",
    "# Start training\n",
    "epochs = 10  # Set number of epochs\n",
    "loss_list = []  # Store loss history\n",
    "model1.train()  # Set model to training mode\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = []\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad(set_to_none=True)  # Initialize gradient\n",
    "        output = model1(data)  # Forward pass\n",
    "        loss = loss_func(output, target)  # Calculate loss\n",
    "        loss.backward()  # Backward pass\n",
    "        optimizer.step()  # Optimize weights\n",
    "        total_loss.append(loss.item())  # Store loss\n",
    "    loss_list.append(sum(total_loss) / len(total_loss))\n",
    "    print(\"Training [{:.0f}%]\\tLoss: {:.4f}\".format(100.0 * (epoch + 1) / epochs, loss_list[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a330e8",
   "metadata": {},
   "source": [
    "学習には数分かかりますので、その間にIBM Cloudでの呼び出し方法を見てみましょう。\n",
    "学習を終えると、`torch.save` メソッドでモデルを保存できます。このモデルを利用したCloud上のアプリで、手書き文字を認識してみましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2391217a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![Sample Application on IBM Cloud](Cloud1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5769c1c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![Architecture on IBM Cloud](Cloud2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511d3c2e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "学習が終わったら、学習の様子をプロットしてみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c0eef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss convergence\n",
    "plt.plot(loss_list)\n",
    "plt.title(\"Hybrid NN Training Convergence\")\n",
    "plt.xlabel(\"Training Iterations\")\n",
    "plt.ylabel(\"Neg. Log Likelihood Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c94cf16",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "モデルを保存して学習は終了です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae2b834",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model1.state_dict(), \"model1.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2d35d9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### ステップ4: テスト \n",
    "保存したモデルを、実行用にロードします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3339d070",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create a new instance of Hybrid QNN and load trained model\n",
    "qnn2 = create_qnn()\n",
    "model2 = Net(qnn2)\n",
    "model2.load_state_dict(torch.load(\"model1.pt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabefaf1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "テストデータを分類してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214699b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.eval()  # set model to evaluation mode\n",
    "with no_grad():\n",
    "\n",
    "    correct = 0\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        output = model2(data)\n",
    "        if len(output.shape) == 1:\n",
    "            output = output.reshape(1, *output.shape)\n",
    "\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        loss = loss_func(output, target)\n",
    "        total_loss.append(loss.item())\n",
    "\n",
    "    print(\n",
    "        \"Performance on test data:\\n\\tLoss: {:.4f}\\n\\tAccuracy: {:.1f}%\".format(\n",
    "            sum(total_loss) / len(total_loss), correct / len(test_loader) / batch_size * 100\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a2fe80",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "非常に精度のよいモデルができたようですね。実際の予測結果を6件表示させてみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5330042",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Plot predicted labels\n",
    "\n",
    "n_samples_show = 6\n",
    "count = 0\n",
    "fig, axes = plt.subplots(nrows=1, ncols=n_samples_show, figsize=(10, 3))\n",
    "\n",
    "model2.eval()\n",
    "with no_grad():\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        if count == n_samples_show:\n",
    "            break\n",
    "        output = model2(data[0:1])\n",
    "        if len(output.shape) == 1:\n",
    "            output = output.reshape(1, *output.shape)\n",
    "\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "\n",
    "        axes[count].imshow(data[0].numpy().squeeze(), cmap=\"gray\")\n",
    "\n",
    "        axes[count].set_xticks([])\n",
    "        axes[count].set_yticks([])\n",
    "        axes[count].set_title(\"Predicted {}\".format(pred.item()))\n",
    "\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e59cefe",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## まとめ\n",
    "今回は量子古典ハイブリッド・ニューラルネットワークを利用した、手書き文字認識モデルを作成し、IBM Cloud上のWebアプリから使用してみました。\n",
    "Qiskitの`TorchConnector`クラスを使うと、PytorchのワークフローにQiskitの`NewralNetwork`クラスを簡単に組み込むことができます。\n",
    "学習データに応じて、適切な特徴マップ、Ansatzを利用すれば、量子優位性を持ったモデルを作成することができるかもしれません。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c848974",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## 参考文献 <a id='reference'></a>\n",
    "[1] [Torch コネクターおよびハイブリッド QNN](https://qiskit.org/documentation/machine-learning/locale/ja_JP/tutorials/05_torch_connector.html)\n",
    "\n",
    "[2] [PyTorchとQiskitを用いた量子古典ハイブリッド・ニューラル・ネットワーク](https://qiskit.org/textbook/ja/ch-machine-learning/machine-learning-qiskit-pytorch.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1286cdf6",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3>Version Information</h3><table><tr><th>Qiskit Software</th><th>Version</th></tr><tr><td><code>qiskit-terra</code></td><td>0.24.0</td></tr><tr><td><code>qiskit-aer</code></td><td>0.12.0</td></tr><tr><td><code>qiskit-ignis</code></td><td>0.7.1</td></tr><tr><td><code>qiskit-ibmq-provider</code></td><td>0.20.2</td></tr><tr><td><code>qiskit</code></td><td>0.43.0</td></tr><tr><td><code>qiskit-machine-learning</code></td><td>0.6.1</td></tr><tr><th>System information</th></tr><tr><td>Python version</td><td>3.9.13</td></tr><tr><td>Python compiler</td><td>Clang 13.1.6 (clang-1316.0.21.2)</td></tr><tr><td>Python build</td><td>main, May 24 2022 21:28:31</td></tr><tr><td>OS</td><td>Darwin</td></tr><tr><td>CPUs</td><td>4</td></tr><tr><td>Memory (Gb)</td><td>16.0</td></tr><tr><td colspan='2'>Sat Jun 03 14:59:01 2023 JST</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div style='width: 100%; background-color:#d5d9e0;padding-left: 10px; padding-bottom: 10px; padding-right: 10px; padding-top: 5px'><h3>This code is a part of Qiskit</h3><p>&copy; Copyright IBM 2017, 2023.</p><p>This code is licensed under the Apache License, Version 2.0. You may<br>obtain a copy of this license in the LICENSE.txt file in the root directory<br> of this source tree or at http://www.apache.org/licenses/LICENSE-2.0.<p>Any modifications or derivative works of this code must retain this<br>copyright notice, and modified files need to carry a notice indicating<br>that they have been altered from the originals.</p></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import qiskit.tools.jupyter\n",
    "\n",
    "%qiskit_version_table\n",
    "%qiskit_copyright"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32696bc7",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "ワークショップ、セッション、および資料は、IBMまたはセッション発表者によって準備され、それぞれ独自の見解を反映したものです。それらは情報提供の目的のみで提供されており、いかなる参加者に対しても法律的またはその他の指導や助言を意図したものではなく、またそのような結果を生むものでもありません。本講演資料に含まれている情報については、完全性と正確性を期するよう努力しましたが、「現状のまま」提供され、明示または暗示にかかわらずいかなる保証も伴わないものとします。本講演資料またはその他の資料の使用によって、あるいはその他の関連によって、いかなる損害が生じた場合も、IBMは責任を負わないものとします。本講演資料に含まれている内容は、IBMまたはそのサプライヤーやライセンス交付者からいかなる保証または表明を引きだすことを意図したものでも、IBMソフトウェアの使用を規定する適用ライセンス契約の条項を変更することを意図したものでもなく、またそのような結果を生むものでもありません。\n",
    "\n",
    "本講演資料でIBM製品、プログラム、またはサービスに言及していても、IBMが営業活動を行っているすべての国でそれらが使用可能であることを暗示するものではありません。本講演資料で言及している製品リリース日付や製品機能は、市場機会またはその他の要因に基づいてIBM独自の決定権をもっていつでも変更できるものとし、いかなる方法においても将来の製品または機能が使用可能になると確約することを意図したものではありません。本講演資料に含まれている内容は、参加者が開始する活動によって特定の販売、売上高の向上、またはその他の結果が生じると述べる、または暗示することを意図したものでも、またそのような結果を生むものでもありません。パフォーマンスは、管理された環境において標準的なIBMベンチマークを使用した測定と予測に基づいています。ユーザーが経験する実際のスループットやパフォーマンスは、ユーザーのジョブ・ストリームにおけるマルチプログラミングの量、入出力構成、ストレージ構成、および処理されるワークロードなどの考慮事項を含む、数多くの要因に応じて変化します。したがって、個々のユーザーがここで述べられているものと同様の結果を得られると確約するものではありません。\n",
    "\n",
    "記述されているすべてのお客様事例は、それらのお客様がどのようにIBM製品を使用したか、またそれらのお客様が達成した結果の実例として示されたものです。実際の環境コストおよびパフォーマンス特性は、お客様ごとに異なる場合があります。\n",
    "\n",
    "IBM、IBM ロゴ、ibm.com、IBM Cloud、Qiskitは、世界の多くの国で登録されたInternational  Business  Machines  Corporationの商標です。他の製品名およびサービス名等は、それぞれIBMまたは各社の商標である場合があります。現時点でのIBM の商標リストについては、www.ibm.com/legal/copytrade.shtml をご覧ください。\n",
    "\n",
    "Red HatおよびOpenShift は、米国およびその他の国における Red Hat, Inc. またはその子会社の登録商標です。\n",
    "\n",
    "JupyterはNumFOCUS foundationの登録商標です。\n",
    "\n",
    "PythonはPython Software Foundationの登録商標です。\n",
    "\n",
    "その他のすべての商標は、それぞれの所有者に帰属します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bf3141",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
